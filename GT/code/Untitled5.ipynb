{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "IZnzM6-ZWlGX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(generator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "    nn.Linear(128, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 784),\n",
        "    nn.Tanh()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    return self.main(input)"
      ],
      "metadata": {
        "id": "uBmcPXHQHqL0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(discriminator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "    nn.Linear(784, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(256, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "    return self.main(input)\n",
        "  plt.rcParams['image.cmap'] = 'gray'\n",
        "  def show_images(images):\n",
        "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    for index,image in enumerate(images):\n",
        "        plt.subplot(sqrtn, sqrtn, index+1)\n",
        "        plt.imshow(image.reshape(28, 28))\n",
        "  def d_loss_function(inputs, targets):\n",
        "    return nn.BCELoss()(inputs, targets)\n",
        "\n",
        "  def g_loss_function(inputs):\n",
        "    targets = torch.ones([inputs.shape[0], 1])\n",
        "    targets = targets.to(device)\n",
        "    return nn.BCELoss()(inputs, targets)\n"
      ],
      "metadata": {
        "id": "mrVa8G1FHrS6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print('GPU State:', device)\n",
        "\n",
        "# Model\n",
        "G = generator().to(device)\n",
        "D = discriminator().to(device)\n",
        "print(G)\n",
        "print(D)\n",
        "\n",
        "# Settings\n",
        "epochs = 200\n",
        "lr = 0.0002\n",
        "batch_size = 64\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load data\n",
        "train_set = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST('mnist/', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "for epoch in range(epochs):\n",
        "  epoch += 1\n",
        "  for times, data in enumerate(train_loader):\n",
        "    times += 1\n",
        "    real_inputs = data[0].to(device)\n",
        "    test = 255 * (0.5 * real_inputs[0] + 0.5)\n",
        "    real_inputs = real_inputs.view(-1, 784)\n",
        "    real_outputs = D(real_inputs)\n",
        "    real_label = torch.ones(real_inputs.shape[0], 1).to(device)\n",
        "    noise = (torch.rand(real_inputs.shape[0], 128) - 0.5) / 0.5\n",
        "    noise = noise.to(device)\n",
        "    fake_inputs = G(noise)\n",
        "    fake_outputs = D(fake_inputs)\n",
        "    fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\n",
        "    outputs = torch.cat((real_outputs, fake_outputs), 0)\n",
        "    targets = torch.cat((real_label, fake_label), 0)\n",
        "    \n",
        "    # Zero the parameter gradients\n",
        "    d_optimizer.zero_grad()\n",
        "\n",
        "    # Backward propagation\n",
        "    d_loss = d_loss_function(outputs, targets)\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    # Generator\n",
        "    noise = (torch.rand(real_inputs.shape[0], 128)-0.5)/0.5\n",
        "    noise = noise.to(device)\n",
        "    fake_inputs = G(noise)\n",
        "    fake_outputs = D(fake_inputs)\n",
        "    g_loss = g_loss_function(fake_outputs)\n",
        "    g_optimizer.zero_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "    if times % 100 == 0 or times == len(train_loader):\n",
        "      print('[{}/{}, {}/{}] D_loss: {:.3f} G_loss: {:.3f}'.format(epoch, epochs, timimgs_numpy = (fake_inputs.data.cpu().numpy()+1.0)/2.0))\n",
        "    show_images(imgs_numpy[:16])\n",
        "    plt.show()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "      torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n",
        "      print('Model saved.')\n",
        "print('Training Finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "cV9dX0H1IIYu",
        "outputId": "49d55c3b-2503-43c2-9c3e-fb2a5c9e8044"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU State: cpu\n",
            "generator(\n",
            "  (main): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (5): Tanh()\n",
            "  )\n",
            ")\n",
            "discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.2)\n",
            "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
            "    (5): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-0d55416d8213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'd_loss_function' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "XKVc0F5BXlCA"
      }
    }
  ]
}